{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":30746,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n        \nfrom sklearn.datasets import load_digits\nfrom sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.metrics import roc_auc_score\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder , StandardScaler\nfrom sklearn.impute import SimpleImputer\n\n    \n\ntrain_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n\n\n# Handle missing values (you can use different strategies based on your needs)\ntrain_data['Age'].fillna(train_data['Age'].median(),)\ntest_data['Age'].fillna(test_data['Age'].median(),)\ntrain_data['Fare'].fillna(test_data['Fare'].median(),)\ntest_data['Fare'].fillna(test_data['Fare'].median(),)\ntrain_data['Embarked'].fillna(train_data['Embarked'].mode()[0],)\ntest_data['Embarked'].fillna(test_data['Embarked'].mode()[0],)\n\n# Create binary 'HasCabin' feature\ntrain_data['Cabin'] = train_data['Cabin'].apply(lambda x: 0 if pd.isnull(x) else 1)\ntest_data['Cabin'] = test_data['Cabin'].apply(lambda x: 0 if pd.isnull(x) else 1)\n\n#Encoding column\n\nlabelencoder_sex = LabelEncoder()\ntrain_data['Sex'] = labelencoder_sex.fit_transform(train_data['Sex'])\ntest_data['Sex'] = labelencoder_sex.transform(test_data['Sex'])\n\n# OneHotEncode 'Embarked' column\nonehotencoder_embarked = OneHotEncoder(sparse_output=False, drop='first')\nembarked_train = onehotencoder_embarked.fit_transform(train_data[['Embarked']])\nembarked_test = onehotencoder_embarked.transform(test_data[['Embarked']])\n\n# Append OneHotEncoded 'Embarked' back to dataframes\nembarked_train_df = pd.DataFrame(embarked_train, columns=onehotencoder_embarked.get_feature_names_out(['Embarked']))\nembarked_test_df = pd.DataFrame(embarked_test, columns=onehotencoder_embarked.get_feature_names_out(['Embarked']))\n\ntrain_data = train_data.join(embarked_train_df)\ntest_data = test_data.join(embarked_test_df)\n\n\n# Scaling features\nscaler = StandardScaler()\ntrain_data[['Age', 'Fare']] = scaler.fit_transform(train_data[['Age', 'Fare']])\ntest_data[['Age', 'Fare']] = scaler.transform(test_data[['Age', 'Fare']])\n\n\n# Applying manual weights\ntrain_data['Pclass_weighted'] = train_data['Pclass'] * 0.5\ntest_data['Pclass_weighted'] = test_data['Pclass'] * 0.5\n\ntrain_data['Sex_weighted'] = train_data['Sex'] * 0.5\ntest_data['Sex_weighted'] = test_data['Sex'] * 0.5\n\ntrain_data['Age_weighted'] = train_data['Age'] * 1.2\ntest_data['Age_weighted'] = test_data['Age'] * 1.2\n\ntrain_data['SibSp_weighted'] = train_data['SibSp'] * 0.8\ntest_data['SibSp_weighted'] = test_data['SibSp'] * 0.8\n\ntrain_data['Parch_weighted'] = train_data['Parch'] * 1.2\ntest_data['Parch_weighted'] = test_data['Parch'] * 1.2\n\ntrain_data['Fare_weighted'] = train_data['Fare'] * 1.5\ntest_data['Fare_weighted'] = test_data['Fare'] * 1.5\n\ntrain_data['Cabin_weighted'] = train_data['Cabin'] * 1.7\ntest_data['Cabin_weighted'] = test_data['Cabin'] * 1.7\n\n# Include OneHotEncoded 'Embarked' columns in weights\nfor col in onehotencoder_embarked.get_feature_names_out(['Embarked']):\n    train_data[f'{col}_weighted'] = train_data[col] * 0\n    test_data[f'{col}_weighted'] = test_data[col] * 0\n\n\n# Preparing features\nfeatures = ['Pclass_weighted', 'Sex_weighted', 'Age_weighted', 'SibSp_weighted', 'Parch_weighted', 'Fare_weighted','Cabin_weighted'] + [f'{col}_weighted' for col in onehotencoder_embarked.get_feature_names_out(['Embarked'])]\nfeatures += [f'{col}_weighted' for col in onehotencoder_embarked.get_feature_names_out(['Embarked'])]\nX = train_data[features].copy()\ny = train_data['Survived'].copy()\n\n\n# Splitting the testing data into, for accuracy testing\nX_train, X_val ,y_train,y_val = train_test_split(X,y, test_size = 0.2, random_state = 42, stratify =y)\n\n\n# Impute NaN values with mean\nimputer = SimpleImputer(strategy='median')\nX_train = imputer.fit_transform(X_train)\nX_val = imputer.transform(X_val)\nX_test = imputer.transform(test_data[features])\n\n# Define the classifier\nclf = RandomForestClassifier()\n\n# Fit the model\nclf.fit(X_train, y_train)\n\n#print (clf.score(X_train, y_train))\n#print(clf.score(testing, testing_labels))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-24T11:42:13.715153Z","iopub.execute_input":"2024-07-24T11:42:13.716133Z","iopub.status.idle":"2024-07-24T11:42:14.011973Z","shell.execute_reply.started":"2024-07-24T11:42:13.716096Z","shell.execute_reply":"2024-07-24T11:42:14.010720Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n0.9859550561797753\n","output_type":"stream"}]},{"cell_type":"code","source":"pred = clf.predict(X_train)\npred = (pred>0.5).astype(int)\n\naccuracy = clf.score(X_train, y_train)\nprint(f\"Accuracy Score: {accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-24T11:46:14.363768Z","iopub.execute_input":"2024-07-24T11:46:14.364187Z","iopub.status.idle":"2024-07-24T11:46:14.402490Z","shell.execute_reply.started":"2024-07-24T11:46:14.364142Z","shell.execute_reply":"2024-07-24T11:46:14.401466Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Accuracy Score: 0.9859550561797753\n","output_type":"stream"}]},{"cell_type":"code","source":"# Predicting \ny_pred = clf.predict(X_test)\ny_pred = (y_pred>0.5).astype(int)\ny_pred_flat = y_pred.flatten()\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': y_pred_flat})\noutput.to_csv('submission.csv', index=False)\n\n#accuracy = clf.score(X_train, y_train)\n#print(f\"Accuracy Score: {y_pred_flat}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-24T11:48:24.125008Z","iopub.execute_input":"2024-07-24T11:48:24.125390Z","iopub.status.idle":"2024-07-24T11:48:24.149891Z","shell.execute_reply.started":"2024-07-24T11:48:24.125362Z","shell.execute_reply":"2024-07-24T11:48:24.148857Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Accuracy Score: [0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1 0 0\n 0 0 1 0 0 0 1 1 0 0 0 1 0 1 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 1 1 1 0 1 0\n 1 0 0 1 0 1 1 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0\n 1 1 1 1 0 0 1 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0\n 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0\n 1 1 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 1 1 1 0 0 0 1 1 0 1 0 1 0 1 0 0 0 0 0 1\n 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n 1 0 0 0 0 1 0 0 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 1 1 0\n 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 1 0 1 0 0 1 0 1 1 1 1 0 0 0 1 0\n 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 1 1 0\n 0 1 1 1 1 1 0 1 0 0 0]\n","output_type":"stream"}]}]}