{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":30732,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder , StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom sklearn.metrics import accuracy_score\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\ntrain_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n\n\n# Handle missing values (you can use different strategies based on your needs)\ntrain_data['Age'].fillna(train_data['Age'].median(),)\ntest_data['Age'].fillna(test_data['Age'].median(),)\ntrain_data['Fare'].fillna(test_data['Fare'].median(),)\ntest_data['Fare'].fillna(test_data['Fare'].median(),)\ntrain_data['Embarked'].fillna(train_data['Embarked'].mode()[0],)\ntest_data['Embarked'].fillna(test_data['Embarked'].mode()[0],)\n\n# Create binary 'HasCabin' feature\ntrain_data['Cabin'] = train_data['Cabin'].apply(lambda x: 0 if pd.isnull(x) else 1)\ntest_data['Cabin'] = test_data['Cabin'].apply(lambda x: 0 if pd.isnull(x) else 1)\n\n#Encoding column\n\nlabelencoder_sex = LabelEncoder()\ntrain_data['Sex'] = labelencoder_sex.fit_transform(train_data['Sex'])\ntest_data['Sex'] = labelencoder_sex.transform(test_data['Sex'])\n\n# OneHotEncode 'Embarked' column\nonehotencoder_embarked = OneHotEncoder(sparse_output=False, drop='first')\nembarked_train = onehotencoder_embarked.fit_transform(train_data[['Embarked']])\nembarked_test = onehotencoder_embarked.transform(test_data[['Embarked']])\n\n# Append OneHotEncoded 'Embarked' back to dataframes\nembarked_train_df = pd.DataFrame(embarked_train, columns=onehotencoder_embarked.get_feature_names_out(['Embarked']))\nembarked_test_df = pd.DataFrame(embarked_test, columns=onehotencoder_embarked.get_feature_names_out(['Embarked']))\n\ntrain_data = train_data.join(embarked_train_df)\ntest_data = test_data.join(embarked_test_df)\n\n\n# Scaling features\nscaler = StandardScaler()\ntrain_data[['Age', 'Fare']] = scaler.fit_transform(train_data[['Age', 'Fare']])\ntest_data[['Age', 'Fare']] = scaler.transform(test_data[['Age', 'Fare']])\n\n\n# Applying manual weights\ntrain_data['Pclass_weighted'] = train_data['Pclass'] * 0.5\ntest_data['Pclass_weighted'] = test_data['Pclass'] * 0.5\n\ntrain_data['Sex_weighted'] = train_data['Sex'] * 0.5\ntest_data['Sex_weighted'] = test_data['Sex'] * 0.5\n\ntrain_data['Age_weighted'] = train_data['Age'] * 1.2\ntest_data['Age_weighted'] = test_data['Age'] * 1.2\n\ntrain_data['SibSp_weighted'] = train_data['SibSp'] * 0.8\ntest_data['SibSp_weighted'] = test_data['SibSp'] * 0.8\n\ntrain_data['Parch_weighted'] = train_data['Parch'] * 1.2\ntest_data['Parch_weighted'] = test_data['Parch'] * 1.2\n\ntrain_data['Fare_weighted'] = train_data['Fare'] * 1.5\ntest_data['Fare_weighted'] = test_data['Fare'] * 1.5\n\ntrain_data['Cabin_weighted'] = train_data['Cabin'] * 1.7\ntest_data['Cabin_weighted'] = test_data['Cabin'] * 1.7\n\n# Include OneHotEncoded 'Embarked' columns in weights\nfor col in onehotencoder_embarked.get_feature_names_out(['Embarked']):\n    train_data[f'{col}_weighted'] = train_data[col] * 0\n    test_data[f'{col}_weighted'] = test_data[col] * 0\n\n\n# Preparing features\nfeatures = ['Pclass_weighted', 'Sex_weighted', 'Age_weighted', 'SibSp_weighted', 'Parch_weighted', 'Fare_weighted','Cabin_weighted'] + [f'{col}_weighted' for col in onehotencoder_embarked.get_feature_names_out(['Embarked'])]\nfeatures += [f'{col}_weighted' for col in onehotencoder_embarked.get_feature_names_out(['Embarked'])]\nX = train_data[features].copy()\ny = train_data['Survived'].copy()\n\n\n# Splitting the testing data into, for accuracy testing\nX_train, X_val ,y_train,y_val = train_test_split(X,y, test_size = 0.2, random_state = 0)\n\n\n# Impute NaN values with mean\nimputer = SimpleImputer(strategy='median')\nX_train = imputer.fit_transform(X_train)\nX_val = imputer.transform(X_val)\nX_test = imputer.transform(test_data[features])\n\n\n# Convert to float32\nX_train = X_train.astype(np.float32)\nX_val = X_val.astype(np.float32)\nX_test = X_test.astype(np.float32)\ny_train = y_train.astype(np.float32)\ny_val = y_val.astype(np.float32)\n\n# initializing the model\nclassifier = Sequential()\n\n# adding the input layer and first hidden layer \n\n\nclassifier.add(Dense (16,  activation = 'relu',input_shape=(X_train.shape[1],) ))\n\nclassifier.add(Dense (4, activation = 'hard_silu'))\n\nclassifier.add(Dense (2, activation = 'leaky_relu'))\n\n# adding the output layer\nclassifier.add(Dense(1, activation = 'sigmoid' ))\n#classifier.add(Dropout(0.2))\n# compiling the ANN \nclassifier.compile(optimizer = 'adamw', loss = 'binary_crossentropy', metrics=['accuracy'])\n\n# fitting the ANN to the training set\nclassifier.fit(X_train, y_train, batch_size= 25, epochs= 500)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = classifier.predict(X_train)\npred = (pred>0.5).astype(int)\n\naccuracy = accuracy_score(y_train, pred)\nprint(f\"Accuracy Score: {accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-18T22:31:30.164149Z","iopub.execute_input":"2024-07-18T22:31:30.164619Z","iopub.status.idle":"2024-07-18T22:31:30.395481Z","shell.execute_reply.started":"2024-07-18T22:31:30.164576Z","shell.execute_reply":"2024-07-18T22:31:30.394277Z"},"trusted":true},"execution_count":366,"outputs":[{"name":"stdout","text":"\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\nAccuracy Score: 0.8539325842696629\n","output_type":"stream"}]},{"cell_type":"code","source":"# Predicting \ny_pred = classifier.predict(X_test)\ny_pred = (y_pred>0.5).astype(int)\ny_pred_flat = y_pred.flatten()\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': y_pred_flat})\noutput.to_csv('submission.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-18T22:31:30.396919Z","iopub.execute_input":"2024-07-18T22:31:30.397322Z","iopub.status.idle":"2024-07-18T22:31:30.538143Z","shell.execute_reply.started":"2024-07-18T22:31:30.397290Z","shell.execute_reply":"2024-07-18T22:31:30.536908Z"},"trusted":true},"execution_count":367,"outputs":[{"name":"stdout","text":"\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n","output_type":"stream"}]}]}