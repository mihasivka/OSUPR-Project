{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":30746,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\n# Load data\ntrain_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n\n# Handle missing values\ntrain_data['Age'].fillna(train_data['Age'].median())\ntest_data['Age'].fillna(test_data['Age'].median())\ntrain_data['Fare'].fillna(test_data['Fare'].median())\ntest_data['Fare'].fillna(test_data['Fare'].median())\ntrain_data['Embarked'].fillna(train_data['Embarked'].mode()[0])\ntest_data['Embarked'].fillna(test_data['Embarked'].mode()[0])\n\n# Create binary 'HasCabin' feature\ntrain_data['Cabin'] = train_data['Cabin'].apply(lambda x: 0 if pd.isnull(x) else 1)\ntest_data['Cabin'] = test_data['Cabin'].apply(lambda x: 0 if pd.isnull(x) else 1)\n\n# Encode 'Sex' column\nlabelencoder_sex = LabelEncoder()\ntrain_data['Sex'] = labelencoder_sex.fit_transform(train_data['Sex'])\ntest_data['Sex'] = labelencoder_sex.transform(test_data['Sex'])\n\n# OneHotEncode 'Embarked' column\nonehotencoder_embarked = OneHotEncoder(sparse_output=False, drop='first')\nembarked_train = onehotencoder_embarked.fit_transform(train_data[['Embarked']])\nembarked_test = onehotencoder_embarked.transform(test_data[['Embarked']])\n\n# Append OneHotEncoded 'Embarked' back to dataframes\nembarked_train_df = pd.DataFrame(embarked_train, columns=onehotencoder_embarked.get_feature_names_out(['Embarked']))\nembarked_test_df = pd.DataFrame(embarked_test, columns=onehotencoder_embarked.get_feature_names_out(['Embarked']))\n\ntrain_data = train_data.join(embarked_train_df)\ntest_data = test_data.join(embarked_test_df)\n\n# Scaling features\nscaler = StandardScaler()\ntrain_data[['Age', 'Fare']] = scaler.fit_transform(train_data[['Age', 'Fare']])\ntest_data[['Age', 'Fare']] = scaler.transform(test_data[['Age', 'Fare']])\n\n# Applying manual weights\ntrain_data['Pclass_weighted'] = train_data['Pclass'] * 2\ntest_data['Pclass_weighted'] = test_data['Pclass'] * 1\n\ntrain_data['Sex_weighted'] = train_data['Sex'] * 0.5\ntest_data['Sex_weighted'] = test_data['Sex'] * 0.5\n\ntrain_data['Age_weighted'] = train_data['Age'] * 0.5\ntest_data['Age_weighted'] = test_data['Age'] * 0.5\n\ntrain_data['SibSp_weighted'] = train_data['SibSp'] * 2\ntest_data['SibSp_weighted'] = test_data['SibSp'] * 1\n\ntrain_data['Parch_weighted'] = train_data['Parch'] * 2\ntest_data['Parch_weighted'] = test_data['Parch'] * 1\n\ntrain_data['Fare_weighted'] = train_data['Fare'] * 0.5\ntest_data['Fare_weighted'] = test_data['Fare'] * 0.5\n\ntrain_data['Cabin_weighted'] = train_data['Cabin'] * 2\ntest_data['Cabin_weighted'] = test_data['Cabin'] * 2\n\n# Include OneHotEncoded 'Embarked' columns in weights\nfor col in onehotencoder_embarked.get_feature_names_out(['Embarked']):\n    train_data[f'{col}_weighted'] = train_data[col] * 2\n    test_data[f'{col}_weighted'] = test_data[col] * 2\n\n# Preparing features\nfeatures = ['Pclass_weighted', 'Sex_weighted', 'Age_weighted', 'SibSp_weighted', 'Parch_weighted', 'Fare_weighted', 'Cabin_weighted']\nfeatures += [f'{col}_weighted' for col in onehotencoder_embarked.get_feature_names_out(['Embarked'])]\nX = train_data[features].copy()\ny = train_data['Survived'].copy()\n\n# Splitting the testing data into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\n# Impute NaN values with median\nimputer = SimpleImputer(strategy='median')\nX_train = imputer.fit_transform(X_train)\nX_val = imputer.transform(X_val)\nX_test = imputer.transform(test_data[features])\n\n# RandomForest Classifier\nclf_rf = RandomForestClassifier(random_state=42)\nclf_rf.fit(X_train, y_train)\ny_pred_rf = clf_rf.predict(X_val)\naccuracy_rf = accuracy_score(y_val, y_pred_rf)\nprint(f\"RandomForest Validation Accuracy: {accuracy_rf}\")\n\n# Neural Network Classifier\nX_train_nn = X_train.astype(np.float32)\nX_val_nn = X_val.astype(np.float32)\nX_test_nn = X_test.astype(np.float32)\ny_train_nn = y_train.astype(np.float32)\ny_val_nn = y_val.astype(np.float32)\n\nclassifier = Sequential()\nclassifier.add(Dense(16, activation='relu', input_shape=(X_train_nn.shape[1],)))\nclassifier.add(Dense(4, activation='hard_sigmoid'))\nclassifier.add(Dense(2, activation='leaky_relu'))\nclassifier.add(Dense(1, activation='sigmoid'))\n\nclassifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nclassifier.fit(X_train_nn, y_train_nn, batch_size=25, epochs=200, verbose=0)\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-25T13:24:37.476177Z","iopub.execute_input":"2024-07-25T13:24:37.476610Z","iopub.status.idle":"2024-07-25T13:24:53.488020Z","shell.execute_reply.started":"2024-07-25T13:24:37.476573Z","shell.execute_reply":"2024-07-25T13:24:53.486702Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"RandomForest Validation Accuracy: 0.7932960893854749\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7d7014cd6e60>"},"metadata":{}}]},{"cell_type":"code","source":"y_pred_nn = classifier.predict(X_val_nn)\ny_pred_nn = (y_pred_nn > 0.5).astype(int)\naccuracy_nn = accuracy_score(y_val_nn, y_pred_nn)\nprint(f\"Neural Network Validation Accuracy: {accuracy_nn}\")\n\n# Ensemble: Weighted Averaging\nweight_rf = 0.3\nweight_nn = 0.7\n\ny_pred_rf_prob = clf_rf.predict_proba(X_val)[:, 1]\ny_pred_nn_prob = classifier.predict(X_val_nn).flatten()\n\ny_pred_ensemble = (weight_rf * y_pred_rf_prob) + (weight_nn * y_pred_nn_prob)\ny_pred_ensemble = (y_pred_ensemble > 0.5).astype(int)\naccuracy_ensemble = accuracy_score(y_val, y_pred_ensemble)\nprint(f\"Ensemble (Weighted Averaging) Validation Accuracy: {accuracy_ensemble}\")\n\n# Predict on test data using ensemble model\ny_pred_rf_test_prob = clf_rf.predict_proba(X_test)[:, 1]\ny_pred_nn_test_prob = classifier.predict(X_test_nn).flatten()\ny_pred_ensemble_test = (weight_rf * y_pred_rf_test_prob) + (weight_nn * y_pred_nn_test_prob)\ny_pred_ensemble_test = (y_pred_ensemble_test > 0.5).astype(int)","metadata":{"execution":{"iopub.status.busy":"2024-07-25T13:24:53.490178Z","iopub.execute_input":"2024-07-25T13:24:53.490516Z","iopub.status.idle":"2024-07-25T13:24:53.890070Z","shell.execute_reply.started":"2024-07-25T13:24:53.490487Z","shell.execute_reply":"2024-07-25T13:24:53.888990Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\nNeural Network Validation Accuracy: 0.7932960893854749\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \nEnsemble (Weighted Averaging) Validation Accuracy: 0.8100558659217877\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n","output_type":"stream"}]},{"cell_type":"code","source":"# Save predictions to CSV\nsubmission = pd.DataFrame({\n    \"PassengerId\": test_data[\"PassengerId\"],\n    \"Survived\": y_pred_ensemble_test\n})\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-25T13:24:53.891549Z","iopub.execute_input":"2024-07-25T13:24:53.891953Z","iopub.status.idle":"2024-07-25T13:24:53.900060Z","shell.execute_reply.started":"2024-07-25T13:24:53.891923Z","shell.execute_reply":"2024-07-25T13:24:53.898864Z"},"trusted":true},"execution_count":19,"outputs":[]}]}